---
title: "Advanced Clustering Methods from Post Data"
author: "Bradley Katcher and Aneesh Sandhir"
output: html_document
---

Millions of sites exist that allow individuals to post and answer questions. From personal blogs to sites like Reddit and Stack Exachange, there are a plethora of opportunities for people to interact and help eachother throughout the internet. In doing so, enclave-like internet communities begin to form, where the same individuals respond to the same types of questions and virtually interact with the same kinds of individuals. Throughout this tutorial, we will employ data mining techniques to demonstrate how to identify a set of individuals that engage with the same kind of content online. 

As a case study to demonstrate the formation of online communities, we will walk through an analysis of [CrossValidated](https://stats.stackexchange.com/) users. The data set that we have is pulled from Stack Exchange's Data Explorer Tool. It contains all posts answered by users with a reputation score over 10,000. The data consist of 42,739 individual observations (at the question level), answered by 104 different users. 

```{r eval = TRUE, include = FALSE}
data <- read.csv(url('https://raw.githubusercontent.com/bkatcher4/DataMiningFinal/master/question_metrics_power_users.csv'))

#remove accepted_a_id
data <- subset(data, select = -c(accepted_a_id) )
```




We can preview the first six rows of data here: 
```{r eval = TRUE, echo = FALSE}
head(data)
names <- c(23:126)
data[,names] <- lapply(data[,names] , factor)
```

We first conducted some feature engineering. As you can see, we have the question number, an indicator for whether the question was answered, the number of characters and words in the body of the question and the title of the question, the number of tags on the post, the number of tags in the body, the number of tags in the title, the number of paragraphs in the body, the number of code snippets, the number of plots, the number of "stop words" (words that don't mean anything in a natural langauage processing context such as articles, prepositions, etc.), the number of question marks in the title, the number of question marks in the body, the minimum tag popularity, the minimum tag popularity score, the minimum tag answered ratio, maximum tag popularity, maximum tag popularity score, maximum tag answered ratio, and one-hot encoding for whether a given user answered the question. 

This data represents characteristics about the questions and is very similar to data that could be scraped and created (via feature engieering) from any given forum site, such as Reddit, Quora, or another quesiton and answer-oriented site. From this data, we seek to get information regarding our users. In order to do this, we are going to run a series of regression models predicting their likelihood of answering a question. We do this in order to obtain beta coefficients for users which indicate their propensity for answering the question. Since the outcome is binary regarding whether someone answered the question, we intend to utilize logistic regression. These coefficients represent the log odds ratio of the impact of a certain variable (for example, the verbosity of the post), and so we know that users with similar coefficient values have similar propensities to respond to a certain question with that characteristic. 

Therefore, we build a dataset containing 104 observations (one for each user) contianing their vector of betas. We run a seperate logistic regression for each user where the outcome is whether they answer the question and the predictors are a vector of question characteristics. While in theory, we could employ other types of regression, i.e. logsitic LASSO, logistic ridge, or logistic elastic net (thereby adding a penalty term to the regression, and beneficial for conducting variable selection), we do not because of certain users only answering a few questions, e.g. User 8 only answers 4 questions, and to run 10-fold crossvalidation on that would be impractical due to some folds thus not having any "answered" outcomes, and the length of time it would take to run 104 10-fold crossvalidation regressions.


# Regression Model:

###: Simple Logistic Regression
```{r eval = TRUE}
library(tibble)

# intialize tibble to store coefficients
linear_model_betas <- tibble(name.repair=c("X1", 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11'))

# loop across all users
for(user in 1:104){
  
  (user)
  #subset data frame
  answered_by_user <- data[,c(3:22, (user+22))]
  
  # run model
  model <- glm(answered_by_user[,ncol(answered_by_user)] ~ n_paragraphs_body + n_code_snippets + n_stop_words_body + verbosity + n_tags_title + ques_marks_title + min_tag_answered_ratio + max_tag_popularity + max_tag_answered_ratio + max_tag_popularity_score, family = binomial(link = "logit"), data = answered_by_user)
  
  # store beta coefficients in a local
  beta_i <- model$coefficients
  
  # add beta coefficients to data frame
  linear_model_betas <- cbind(linear_model_betas, beta_i)
}

#remove X labels
linear_model_betas <- linear_model_betas[,-1]

#rename variables in tibble 
tibble_names <- names(data[,names])
colnames(linear_model_betas) <- tibble_names

```

Using this regression, we end up with a dataset containing data regarding the impact of each of the factors we identify on the likelihood that a given user will answer a question. We can preview the dataset below:

```{r eval = TRUE}
# Transpose the dataset so that the users are the observations and the varaibles are the variables:
t_lmb = t(linear_model_betas)
head(t_lmb)
```

Now that we have our dataset, we can begin conducint clustering analysis to see similarities in the characterisitcs of users who answer similar questions. In order to do this, we decide to explore different metrics of distance between users, as well as different ways of clustering users. We will begin by employing hierarchical clustering, then K-means cluster, and explore other types of clustering such as c-means clustering and spectral clustering. 

## Hierarchical Clustering 

We begin by computing the pairwise dissimilarity between users, which is defined as the Euclidian distance between points. From this, we conduct hierarchical clustering and create a dendrogram from agglomerative hierarchical clustering. In doing so, we use complete linkage, which computes cluster dissimilarity as the largest dissimilarity between pairs in two sets. Therefore, on the dendrogram below, the height corresponds to the dissimlarity between the most dissimlar points in the two clusters. 

In order to choose the number of clusters (K), we look for regions in the dendrogram where gaps/changes occur in the height of merges, as a large jump in height corresponds to a high dissimilarity between the solutions for k and k-1 clusters. As can be seen from the plot that compares the height to the number of clusters, we see a jump between K=6 and K=7, so we elect to choose K=7 for our clustering. 

```{r eval = TRUE}
#Calculate Maximum distance
t_lmb = t(linear_model_betas)
distance = dist(t_lmb, method="euclidian")

#clustering
clust = hclust(distance, method="complete")      # complete linkage

#plots
plot(as.dendrogram(clust), las=1, leaflab="none", main = "Complete Linkage Clustering Dendrogram", ylab = "Height")
n = length(clust$height)     # get number of merges

plot(n:1, clust$height, type='o', xlab="K", ylab="height", las=1, 
     xlim=c(1, 52))
points(7, clust$height[n-6], col="red", pch=19) # K=7

clusterNum <- cutree(clust, k=7)     # cut so K=7
clusterData <- data.frame(cbind(clusterNum,t_lmb))
```

From here, we can determine the number of individuals in each cluster, telling us how these most active users group together:

```{r eval = TRUE}
# Produces a tbale of the number of individuals in each cluster:
table(clusterNum)
```
From this result, we can learn a lot about which CrossValidated users try to answer similar questions. There is a group of exactly half of the top users that tend to answer the same kinds of questions, competing with eachother for the best answer and reputation points, while there are several smaller groups as well. Groups of 24, 10, and 15 people. In addition, there are three individuals that seem to be "in a league of their own", meaning that they do not seem to answer the same questions as others. It's worthwhile to try and explore who these individuals are:

```{r eval = TRUE}
rownames(clusterData[clusterData$clusterNum>4,])
```
We can see that these three "unique" users are users number 8, 251, and 8373. 

## K-Means Clustering


# C-Means Clustering
```{r eval = TRUE}
library(ppclust)
res.fcm <- fcm(t_lmb, centers=11)

as.data.frame(res.fcm$u)[1:6,]

```

```{r eval = TRUE}
library("cluster")
library("factoextra")
library("magrittr")

res.dist <- get_dist(t_lmb, stand = TRUE, method = "pearson")
fviz_dist(res.dist, 
   gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

